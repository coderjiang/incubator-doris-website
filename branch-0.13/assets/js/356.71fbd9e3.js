(window.webpackJsonp=window.webpackJsonp||[]).push([[356],{797:function(s,a,t){"use strict";t.r(a);var r=t(55),e=Object(r.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"资源管理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#资源管理"}},[s._v("#")]),s._v(" 资源管理")]),s._v(" "),t("p",[s._v("为了节省Doris集群内的计算、存储资源，Doris需要引入一些其他外部资源来完成相关的工作，如Spark/GPU用于查询，HDFS/S3用于外部存储，Spark/MapReduce用于ETL等，因此我们引入资源管理机制来管理Doris使用的这些外部资源。")]),s._v(" "),t("h2",{attrs:{id:"基本概念"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基本概念"}},[s._v("#")]),s._v(" 基本概念")]),s._v(" "),t("p",[s._v("一个资源包含名字、类型等基本信息，名字为全局唯一，不同类型的资源包含不同的属性，具体参考各资源的介绍。")]),s._v(" "),t("p",[s._v("资源的创建和删除只能由拥有 "),t("code",[s._v("admin")]),s._v(" 权限的用户进行操作。一个资源隶属于整个Doris集群。拥有 "),t("code",[s._v("admin")]),s._v(" 权限的用户可以将使用权限"),t("code",[s._v("usage_priv")]),s._v(" 赋给普通用户。可参考"),t("code",[s._v("HELP GRANT")]),s._v("或者权限文档。")]),s._v(" "),t("h2",{attrs:{id:"具体操作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#具体操作"}},[s._v("#")]),s._v(" 具体操作")]),s._v(" "),t("p",[s._v("资源管理主要有三个命令："),t("code",[s._v("CREATE RESOURCE")]),s._v("，"),t("code",[s._v("DROP RESOURCE")]),s._v(" 和 "),t("code",[s._v("SHOW RESOURCES")]),s._v("，分别为创建、删除和查看资源。这三个命令的具体语法可以通过MySQL客户端连接到 Doris 后，执行 "),t("code",[s._v("HELP cmd")]),s._v(" 的方式查看帮助。")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("CREATE RESOURCE")]),s._v(" "),t("p",[s._v("语法")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("EXTERNAL"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" RESOURCE "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"resource_name"')]),s._v("                                  \n  PROPERTIES "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"key"')]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"value"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n")])])]),t("p",[s._v("在创建资源的命令中，用户必须提供以下信息：")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("resource_name")]),s._v(" 为 Doris 中配置的资源的名字。")]),s._v(" "),t("li",[t("code",[s._v("PROPERTIES")]),s._v(" 是资源相关参数，如下：\n"),t("ul",[t("li",[t("code",[s._v("type")]),s._v("：资源类型，必填，目前仅支持 spark。")]),s._v(" "),t("li",[s._v("其他参数见各资源介绍。")])])])])]),s._v(" "),t("li",[t("p",[s._v("DROP RESOURCE")]),s._v(" "),t("p",[s._v("该命令可以删除一个已存在的资源。具体操作见："),t("code",[s._v("HELP DROP RESOURCE")])])]),s._v(" "),t("li",[t("p",[s._v("SHOW RESOURCES")]),s._v(" "),t("p",[s._v("该命令可以查看用户有使用权限的资源。具体操作见："),t("code",[s._v("HELP SHOW RESOURCES")])])])]),s._v(" "),t("h2",{attrs:{id:"支持的资源"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#支持的资源"}},[s._v("#")]),s._v(" 支持的资源")]),s._v(" "),t("p",[s._v("目前仅支持Spark资源，完成ETL工作。下面的示例都以Spark资源为例。")]),s._v(" "),t("h3",{attrs:{id:"spark"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark"}},[s._v("#")]),s._v(" Spark")]),s._v(" "),t("h4",{attrs:{id:"参数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#参数"}},[s._v("#")]),s._v(" 参数")]),s._v(" "),t("h5",{attrs:{id:"spark-相关参数如下"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark-相关参数如下"}},[s._v("#")]),s._v(" Spark 相关参数如下：")]),s._v(" "),t("p",[t("code",[s._v("spark.master")]),s._v(": 必填，目前支持yarn，spark://host:port。")]),s._v(" "),t("p",[t("code",[s._v("spark.submit.deployMode")]),s._v(": Spark 程序的部署模式，必填，支持 cluster，client 两种。")]),s._v(" "),t("p",[t("code",[s._v("spark.hadoop.yarn.resourcemanager.address")]),s._v(": master为yarn时必填。")]),s._v(" "),t("p",[t("code",[s._v("spark.hadoop.fs.defaultFS")]),s._v(": master为yarn时必填。")]),s._v(" "),t("p",[s._v("其他参数为可选，参考http://spark.apache.org/docs/latest/configuration.html。")]),s._v(" "),t("h5",{attrs:{id:"如果spark用于etl-还需要指定以下参数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#如果spark用于etl-还需要指定以下参数"}},[s._v("#")]),s._v(" 如果Spark用于ETL，还需要指定以下参数：")]),s._v(" "),t("p",[t("code",[s._v("working_dir")]),s._v(": ETL 使用的目录。spark作为ETL资源使用时必填。例如：hdfs://host:port/tmp/doris。")]),s._v(" "),t("p",[t("code",[s._v("broker")]),s._v(": broker 名字。spark作为ETL资源使用时必填。需要使用"),t("code",[s._v("ALTER SYSTEM ADD BROKER")]),s._v(" 命令提前完成配置。")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("broker.property_key")]),s._v(": broker读取ETL生成的中间文件时需要指定的认证信息等。")])]),s._v(" "),t("h4",{attrs:{id:"示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#示例"}},[s._v("#")]),s._v(" 示例")]),s._v(" "),t("p",[s._v("创建 yarn cluster 模式，名为 spark0 的 Spark 资源。")]),s._v(" "),t("div",{staticClass:"language-sql extra-class"},[t("pre",{pre:!0,attrs:{class:"language-sql"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" EXTERNAL RESOURCE "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark0"')]),s._v("\nPROPERTIES\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"type"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.master"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"yarn"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.submit.deployMode"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cluster"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.jars"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"xxx.jar,yyy.jar"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.files"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"/tmp/aaa,/tmp/bbb"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.executor.memory"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"1g"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.yarn.queue"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"queue0"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.hadoop.yarn.resourcemanager.address"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"127.0.0.1:9999"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"spark.hadoop.fs.defaultFS"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hdfs://127.0.0.1:10000"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"working_dir"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hdfs://127.0.0.1:10000/tmp/doris"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"broker"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"broker0"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"broker.username"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"user0"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"broker.password"')]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"password0"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);